= Solution Addressing The Challenges
:navtitle: 2: Addressing Challenge
:numbered:

== Addressing Challenge with AI/ML and MLOps (GitOps):
PM of clothing category along with Marketing Team reviews sentiment analysis and respective comments.
They conclude that cost seems to be a major issue for sentiments and comes up with a discounting offer.
PM approaches data scientist team to come up with an object detection based discount coupon solution.
- Customer goes to a store app or online to take picture of the product which they want to buy.
- Based on the Machine Learning logic, object is detected and a discount is offered.
- Customer keys in this discount online or shows to the Shop Manager for discount.
- Customer avails discount which eventually will turn the sentiments positive.

==

== Addressing Operational Challenges using GitOps:

=== Accessing and testing your deployed Application

As part of the bootstrapping of your environment, an initial instance of
your application was deployed. Let’s review it and confirm it works as
expected.

[arabic]
. Follow the URL marked as `Discount Application url'
* *Discount Application url:* https://object-detection-app-git-retail-Red Hat OpenShift AI-project.{openshift_cluster_ingress_domain}[window=_blank]

. This will open the app in your browser
. You will be prompted to authorize your browser to use your Camera.
Allow it to do so.
. When you take a picture that contains either a piece of clothing,
footwear, or a bottle it should display a rebate overlaid on the image.
. You can also send the URL to your smart phone in order to have a more
portable camera than your laptop

We can now move on to the next step.

=== Retraining the model

The initial version of the discounting model was built using a dataset
called link:discount_data/datasets/monday.csv[monday.csv].

In this section, we will: * log into Red Hat OpenShift AI * Clone the project from your
on-cluster gitea instance * Retrain the model with fresher data *
Publish our changes

==== Logging into Red Hat OpenShift AI

* Locate the Red Hat OpenShift AI URL: {rhodh_dashboard}[window=_blank]
* Click on ``Log in with OpenShift''
* Log in as `user1` with the password `openshift`
* Click *Allow Selected Permissions* to Authorize the access
* Once in the Red Hat OpenShift AI Dashboard, Click on the *Launch Application*
hyperlink in the JupyterHub tile
* Log in as `user1` with the password `openshift`
* Click *Allow Selected Permissions* to Authorize the access
* Choose *Standard Data Science* as the image and *Small* as the
Notebook Size
* Click on *Start Server*

==== Git clone the arc-model project

Each environment comes with a dedicated instance of Gitea so that each
student can easily and independently make updates in the git repo
without affecting the others.

* The Gitea URL to use should be provided together with your environment
information here:
* *Gitea url:* {gitea_console_url}[window=_blank]
+
image:gittea-url.png[gittea-url]
* Once you have the gitea URL:
* Sign in to Gitea as user `lab-user` with password `openshift`.
* Navigate to the *arc-model* git repo.
* Copy the Git Clone URL:
** image:copy-git-url.png[copy-git-url]
* Navigate back to your JupyterLab tab
* Click on the Git Icon (fourth of the 6 big icons on the left)
* Click on the *Clone a repository* button
** image:clone-repo.png[clone-repo]
* Paste the URL and click *Clone*
* In the File Explorer menu, double-click on *arc-model* to move to that
directory

==== Retrain the model

Now that we’ve cloned the project, let’s retrain the model. We will use
a notebook to do so.

* Open the Notebook called `5_discount_model.ipynb` from the Red Hat OpenShift AI file
system tab
* This notebook contains the code for training our discount model.
* In the third cell you can see a reference to our ``monday'' dataset
called `discount_data/datasets/monday.csv`
* Update the content of the cell so that it points to our second
dataset: `discount_data/datasets/tuesday.csv`
* Select the *Run* menu, then the last option: *Restart Kernel and Run
All Cells*
** image:csv-restart-run-all.png[csv-restart-run-all]
* Confirm by clicking *Restart*
* Once all the cells have run, you will notice that some of the files in
the folder *5_discount_models* have been updated.

==== Publish the changes

We have now updated our model files as well as the notebook that was
used to generate them. We will push those changes back into our gitea
instance, in the `main` branch.

* Open up the notebook called `6_git_commit_and_push.ipynb`
* In the third cell, replace the existing command with:
+
`!git add .`
* Once again, run the *Restart Kernel and Run all Cells*
* Doing this will automatically Commit our changes into the local git
repo, and then push those commits back into the Gitea instance.

Note that here, we are storing both the code (notebook) and model
(*.pkl) in Git. If this were a real production project, we’d probably
have a more advanced way of storing the various versions of the model.

=== Reviewing the OpenShift Pipeline

In the previous steps, we pushed our changes back into the Gitea repo.

In this environment, an OpenShift pipeline has been configure to
automatically run every time something is pushed to Gitea.

==== Reviewing the pipeline run

Our dev app should automatically rebuild since that we’ve pushed our
changes to the git repository.

[arabic]
. Follow the link to your `OpenShift Console URL' on your page of URLs.
. Log in to OpenShift using the username: `user1` and password:
`openshift`
. Select `Administrator` view.
image:select-administrator.png[select-administrator]
. Navigate to *Pipelines* , then *Pipelines* (yes, again), and then go
to *PipelineRuns*
image:select-pipelines.png[select-pipelines]
. Make sure that the selected project is *retail-Red Hat OpenShift AI-project*
. You should see a pipeline run that failed on the third step
. Review the failed step.
. Our sanitycheck.py program is a safeguard that ensures the discounts
are never more than a certain percentage.
. It would seem that the new version of the model might be too generous
with the discount!

==== Retrain the model (again).

Let’s fix this! Clearly we had a problem with our data - luckily we
received the data from wednesday which our data engineers have promised
will be correct.

Even more lucky, our pipeline has prevented us from putting a ``bad''
model into our dev environment. Therefore, we don’t even need to worry
about rolling back a bad change: the bad change was prevented from
happening.

[arabic]
. Again, go to `5_discount_model.ipynb` notebook in your Red Hat OpenShift AI tab.
. Let’s use the new data from wednesday, update that same cell as before
to now point to `discount_data/datasets/wednesday.csv`.
. Now, rerun the notebook by clicking *Restart Kernel and Run All* as we
did before.
. This will update the discount model with a new discount model trained
on wednesday’s data.

We could also run the sanity-check here, but the pipeline will take care
of that for us.

[arabic, start=5]
. Run the notebook `6_git_commit_and_push.ipynb` again to commit and
push our model changes to our git repo.

==== Watch the build.

Let’s look at the pipeline build now that we’ve retrained our model with
what should be good data.

[arabic]
. Navigate back to your OpenShift Console tab.
. Again, take a look at the PipelineRuns and click on the latest run
which should be in progress.
. We can click on the sanity check step within our pipeline, view the
log and see that the model has now passed our predefined tests.
. After the sanity check passes, the rest of the pipeline can now
complete and our app will be redeployed with our changes.

=== Reviewing ArgoCD and GitOps

In the previous section, we’ve seen how the pipeline can help detect
potential issues and prevent from implementing ``broken'' artifacts in
our dev environment.

In this section, we will see how OpenShift GitOps is used deploy our
application, and then to maintain its state.

==== Connecting to OpenShift GitOps

* Among the URLs of your environment, locate the *ArgoCD* one.
* When you first open up that URL, you may get a warning that ``your
connection is not private''.
* Click on *Advanced* and then *Proceed to
openshift-gitops…….opentlc.com(unsafe)*.
* You will use the username `admin` and the associated password
(provided with the environment details)
* Once you’re logged into ArgoCD, explore the 2 apps that you see.

==== Attempting a manual change in OpenShift

One way to illustrate the benefits of ArgoCD is to try to perform an
ad-hoc change in OpenShift.

* Open the OpenShift Console.
* Navigate to *Workloads* and then *Deployments*.
* You will see that the deployment called `object-detection-rest`
currently has a single pod (replica)
* If you click on the 3-dots icon at the end of that line, you can
choose to *Edit pod count*.
* Change that `1` into a `5` and click *Save*

By default, ArgoCD will reconcile things every 5 minutes.

In the interest of time, we can trigger this to happen sooner. Let’s see
how. * click on the *retail-dev* app * Once the app is open, click on
*APP DIFF* * Tick the box that says *Compact Diff* * The difference that
you see should make sense * click on *Sync* * click *SYNCHRONIZE*

You will see that doing so will reset things to their original values.
The diff will go away, and the number of pods for this deployment will
go back down to 1.

In fact, you could actually delete a whole lot of things on the
OpenShift side, and ArgoCD would re-create them almost as quickly!

==== Updating things the GitOps way

So if we did want more replicas, what we have to do is to do it in the
Gitea repo, and then get Argo to make that change happen. So let’s do
that.

* Access gitea again
* Make sure you are logged in as `lab-user` with password `openshift`
* Navigate to the repo called `retail-dev-gitops`
* In this repo, stay in the `main` branch
* Navigate to the file `/base/object-detection-rest-deployment.yaml`
* Edit the file directly in Gitea (using the pencil icon)
* Change the text `replicas: 1` to `replicas: 4`
* Commit the change with a meaningful commit message. For example:
image:commit-msg.png[commit-msg]
* Once that is done, toggle over to Argo and get it to refresh again.
* You will quickly see that the number of pods will have been changed in
the target environment as well.

Well, we’ve finally achieved our change, and it’s been implemented in
the cluster. As a bonus, we now have very good traceability on who did
that change when, and it’s also a lot easier to undo it if needed.

=== Wrap up of Hands-On

This concludes the hands-on part of this workshop. Your environment will
not persist much longer after the end of the session, so make sure to
save anything you wish to keep.

We hope you have enjoyed this hands-on and that you have learned a few
new things along the way.

If you have questions, comments, or feedback, feel free to use the Q&A
panel to share it back with us.

== Solution


. Sign in to the Smart Retail Application using the credentials for user 'asilva' to submit feedback for the clothing product, adhering to the details provided below:

+
****
[upperalpha]

.. Find the login details for accessing Smart Retail Application below:
+
TIP: You can skip the login process if you're already signed in.

... *Web Url:* https://globex-web-sentiment-analysis.{openshift_cluster_ingress_domain}[window=_blank]
... *Username:* asilva
... *Password:* openshift


.. Navigate to the 'Coolstore' tab located at the top of the page.


.. Choose the 'T-shirt' and kindly share your thoughts by providing feedback `This is over priced T-shirt` in the designated box.
+
.Smart Retail Application
image::01_coolstore_feedback-4.jpg[coolstore, 640]

****



. Access the Grafana dashboard to monitor historical sentiments for the product. Please log in to view and analyze sentiment trends over time.
+
****
.. Find the login details for accessing RocketChat below:
... *Grafana URL:* https://grafana-route-influxdb-project.{openshift_cluster_ingress_domain}[window=_blank]
... *Username:* admin
... *Password:* {gitea_admin_password}
+
.Grafana Login page
image::08_grafana_login.jpg[Grafana, 400]


.. Access the GLOBEX Sentiment Analysis Dashboard by searching for it in the search bar.
+
.Grafana Dashboard page
image::08_grafana_dashboard-1.jpg[Grafana, 640]

.. Take a moment to observe the sentiments associated with the clothing category.
+
.Grafana Dashboard page
image::08_grafana_dashboard-2.jpg[Grafana, 640]

****


. Access the RocketChat monitoring system to view the latest message posted by the Automation Controller. The details are provided below, offering insights into the formatted feedback generated by the system:

+
****
[upperalpha]

.. Find the login details for accessing RocketChat below:
+
IMPORTANT: Kindly log out and log back in as pm_clothing if you are currently signed in. This will ensure that you have the appropriate access and privileges for the next steps

... *RocketChat Url:* {rocketchat_url}[window=_blank]
... *Username:* pm_clothing
... *Password:* {rocketchat_admin_password}

.. Navigate to the #clothing channel and review the new message that contains the original feedback, along with additional product details.
* Message Content:
** *USER SENTIMENT*: negative,
** *PRODUCT_CATEGORY*: clothing,
** *PRODUCT_ID*: 329299,
** *PRODUCT_NAME*: Quarkus T-shirt,
** *USER NAME*: Addison Silva,
** *REGION*: USA,
** *REVIEW*: his is over priced T-shirt,
** *SCORE:* 2
+
.RocketChat Channel Page
image::05_rocketchat_channel-1.jpg[RocketChat, 640]
****

. As the product manager, your integral role encompasses active engagement with customer feedback and sentiment analysis. After carefully reviewing messages and closely monitoring sentiments, you hold the authority to take decisive action on the product. Leverage the insights gained to craft and send an action message in the #clothing channel, addressing specific actions, production ID, and optionally, price, based on the sentiments observed. Your proactive involvement plays a pivotal role in shaping a positive and customer-centric experience.

+
****
.. As the product manager, after reviewing the negative feedback, you've decided to reduce the price of the T-shirt. To implement this change, you can directly post the command in the #clothing channel as follows: `update,329299,5`. This command will trigger Event-driven Ansible to execute an Automation Controller job template, updating the price of the product in the Smart Retail Application.
+
[NOTE]
====
Here are the three ChatOps action commands available to the Product Manager:

* *Update Price Command:* To update the price of a product, use the command.
+
----
update,ProductID,NewPrice
----

* *Block Product Command:* To block a specific product, issue the command in the respective channel.
+
----
discontinue,ProductID
----

* *Unblock Product Command:* To unblock a specific product, issue the command in the respective channel.
+
----
continue,ProductID
----

Replace ProductID with the product identifier and NewPrice with the updated price for the product

These commands enable the Product Manager to efficiently and directly take actions on products based on the insights gathered from the ChatOps system.
====

.. Kindly wait for the acknowledgement from Event-driven Ansible to ensure the successful execution of the ChatOps command. This confirmation will provide assurance that the requested action has been carried out as intended.
+
.RocketChat Channel Page
image::05_rocketchat_channel-2.jpg[RocketChat, 640]
****


. Navigate to the Event-driven Ansible console and witness the smooth triggering of the Ansible Controller Job Template. This activation occurs when the product manager posts a chatops action in the RocketChat #clothing channel. For detailed insights, please refer to the information provided below:

+
.Optional tasks to verify
****
[upperalpha]

.. Find the login details for accessing Event-driven Ansible below:
+
TIP: You can skip the login process if you're already signed in.

... *Event-driven Ansible:* {eda_controller_web_url}[window=_blank]
... *Username:* {eda_controller_admin_user}
... *Password:* {eda_controller_admin_password}


.. Head to 'Rulebook Activations' and take note of the 'rocketchat-trigger' Fire count, which should reflect an increase of 1. This signifies the successful triggering of the designated rulebook activation. Monitoring this metric is essential for an effective overview of the RocketChat ChatOps integration process.

****


. Access the Automation Controller to observe the job triggered by Event-driven Ansible upon posting the ChatOps action in RocketChat. The Automation Controller job is specifically crafted to update the Smart Retail Application as per the action instruction provided. This functionality ensures that the product manager can efficiently and promptly take necessary actions. For a detailed understanding of this integration process, please refer to the information provided below.

+
.Optional tasks to verify
****
[upperalpha]

.. Find the login details for accessing Automation Controller below:
+
TIP: You can skip the login process if you're already signed in.

... *Automation Controller:* {aap_controller_web_url}[window=_blank]
... *Username:* {aap_controller_admin_user}
... *Password:* {aap_controller_admin_password}


.. Head to 'Jobs' and take note of the latest executed job labeled 'X - chatops-action.' This allows you to review the details of the most recent execution, offering insights into the specific actions taken as a result of the triggered event.

****


. Return to the Smart Retail Application, refresh the page, and locate the same T-shirt to verify any updated price. Refer to the details provided below for accurate information:

+
****
[upperalpha]
.. Go to the 'Coolstore' tab at the top of the page and find the same T-shirt to confirm that the price has been successfully updated..
+
.Smart Retail Appllicaton Page
image::01_coolstore_action-1.jpg[coolstore, 640]

****

== Conclusion
In conclusion, as a Product Manager, the amalgamation of comprehensive data insights from the Grafana dashboard provides a robust understanding of overall and historical customer sentiments within specific product categories. The integration of real-time feedback from our chat system enhances our ability to discern sentiments surrounding specific products. This dynamic combination equips us to make informed decisions, strategically implementing discounts or temporarily disabling items as needed. The synergy between historical trends and live feedback ensures our responsiveness to evolving customer preferences, fostering a customer-centric decision-making process.


*Feel free to continue to the next page for further information or actions.*

== Summary:
As an administrator, seamlessly integrating the ChatOps system with Event-Driven Ansible Architecture proves advantageous for product managers. This streamlined process empowers them to issue commands directly from the chat system, enabling swift changes for specific categories, from applying discounts to disabling particular sections on the online retail website.

*Let's move forward to the next page where we'll delve into the analysis of live messages and the timely execution of actions through ChatOps commands*
